{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpotNN_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReN8gPeav2z5",
        "colab_type": "text"
      },
      "source": [
        "@author: Md Siamul Islam\n",
        "# Parking Spot Vacancy/Occupancy recognition deep NN solution-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUTdUERUbzPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-req (if required)\n",
        "\n",
        "# keras- high-level NN API- CPU&GPU compatibility - backend engine supports: Theano, Tensorflow by default, or CNTK\n",
        "# saving keras models to disk: use HDF5 or h5py\n",
        "# can use Theano for Linus systems - running for first time creates JSON but if reconfiguration necessary: create the file and configure backend\n",
        "# $ pwd\n",
        "# $ mkdir .keras\n",
        "# $ cd .keras/\n",
        "# /.keras$ touch keras.JSON/.keras$ vim keras.json\n",
        "# go to INSERT mode and enter\n",
        "# {\n",
        "# \"image_data_format\":\"channels_first\",\n",
        "# \"epsilon\": le-07,\n",
        "# \"floatx\": \"float32\",\n",
        "# \"backend\": \"theano\"\n",
        "# }\n",
        "# ~\n",
        "# ~\n",
        "# //use \"image_dim_ordering\": \"th\", for first parameter for older keras version or \"tf\" for tensorflow\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iu5s9ll3qOo",
        "colab_type": "text"
      },
      "source": [
        "# VGG16 model ver 2\n",
        "# fine tuned with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wrw6DzZ3xHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2627c780-b840-429c-ad17-273cca654ce6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as k\n",
        "#from tensorflow import keras\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Sequential\n",
        "from keras.layers import Activation\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "#from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "vgg16_model = keras.applications.vgg16.VGG16()\n",
        "vgg16_model.summary()  # can work on 1000 different categories but need only 2 - need to modify the model for our purpose\n",
        "\n",
        "# .model -transform into Sequential model(object)\n",
        "type(vgg16_model)\n",
        "\n",
        "model = Sequential() # model set to sequential object -currently model has no layers\n",
        "# iterating over all layers within vgg16 model and adding those layers to the sequential model\n",
        "# now we have a model of sequential type and don't need to work with functional API\n",
        "# for layer in vgg16_model.layers:\n",
        "#     model.add(layer)\n",
        "\n",
        "# alternatively, iterating over all except last layer in vgg16, adding to seq model- no pop() required\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model classifies images- 1 of 1000 categories, not what we want- need to take off the last predictions output dense layer- use pop()\n",
        "# model.layers.pop()\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# no longer working on VGG16 model variable but the new model variable which is a sequential model\n",
        "# setting the layers shown in summary to false to freeze/exclude in future training so the weights are not updated\n",
        "# good for fine  tuning a model -don't need to update layer weights and keep them same\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# instead of the last prediction layer that we popped off,\n",
        "# a new dense layer is added to the model that classifies images to two categories -for 'empty' and 'occupied'\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XogVcAAAbscu",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Data for training using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8hKmaWgr_cp",
        "colab_type": "text"
      },
      "source": [
        "# Image Preparation\n",
        "-for VGG16 image clasifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGNn4UyNsDKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize directory structure - place image on disk (unless using libraries to handle this)\n",
        "# eg: directories: test, train, valid in some directory spot\n",
        "# eg: spot/train/ has directories: empty and occupied containing images corresponding to those labels\n",
        "# eg valid directory has empty and occupied directories with images for validation - set validation % parameter- between 0 and 1- to take from dataset\n",
        "# typically dump all sorts of unorganized labelled images into test directory; but for known labelled images to test, may create empty and occupied folders w/images to test on\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXLnx5zgcItl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# train_labels = [] # corresponding label for sample - needs to be in numpy array\n",
        "# train_samples = [] # actual image data - numpy array or list of numpy array for eg num data purpose\n",
        "\n",
        "train_path = 'content/sample_data/train'\n",
        "test_path = 'content/sample_data/test'\n",
        "valid_path = 'content/sample_data/valid'\n",
        "\n",
        "# ImageDataGenerator -keras object- to get it formatted to be used by keras model\n",
        "# creates batches of normalized data\n",
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=28)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=4)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=10)\n",
        "\n",
        "# Plotting image with labels on Jupyter Notebook- from git\n",
        "def plots(ims, figsize(12,6), rows=1, interp=False, title=None):\n",
        "  if type(ims[0]) is np.ndarray:\n",
        "    ims = np.array(ims).astype(np.uint8)\n",
        "    if(ims.shape[-1] != 3):\n",
        "      ims = ims.transpose((0,2,3,1))\n",
        "      f = plt.figure(figsize=figsize)\n",
        "      cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "      for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "          sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "\n",
        "imgs, labels = next(train_batches) # gets another batch of size 10 from total of images in training set - gets new batch every time its plotted/run\n",
        "plots(imgs, titles=labels)        # observe labels and see if correct and uniform- encoding - eg: [1. 0.] and [0. 1.] for empty and occupied respectively or vice versa\n",
        "\n",
        "\n",
        "# include code block for grayscale conversion, img normalization-eg.size, etc. & other pre-processing as desired"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKa3Cuz-30rI",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhRXiZXKBc5E",
        "colab_type": "text"
      },
      "source": [
        "# Train the new vgg16 model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7rcVv70Bk40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the new model using Adam optimization function with learning rate 0.0001 and provided functions and metrics\n",
        "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# passing in images from image data generator(code block missing) in training set, steps_per_epoch= (images in dataset)/(batch size), valid set generated from image generator(missing code block),\n",
        "# ..., verbose set to level 2\n",
        "model.fit_generator(train_batches, steps_per_epoch=7,\n",
        "                    validation_data=valid_batches, validation_steps=4, epochs=9, verbose =2)\n",
        "\n",
        "# observe metrics from training- compare with 3X64 node CNN created previously- use the better one\n",
        "# also check for overfitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_r9IplIkzXZ",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmspzMqOk51X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "test_imgs, test_labels = next(test_batches)\n",
        "plots(test_imgs, titles=test_labels)\n",
        "\n",
        "# 0th index so that empty/occupied gets values 0/1 or vice versa\n",
        "test_labels = test_labels[:,0]\n",
        "\n",
        "# set steps according to : test set image count (eg. 10) and batch size: (eg. 10), so it takes 1 step to run through the batch of imgs\n",
        "predictions = model.predict_generator(test_batches, steps=1, verbose=0)\n",
        "\n",
        "# create confusion matrix variable\n",
        "cm = confusion_matrix(test_labels, np.round(predictions[:,0]))\n",
        "\n",
        "cm_plot_labels = ['empty', 'occupied']\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix') # plots predicted labels vs true labels on x-y axis -observe values\n",
        "# accuracy might depend on amount of data used for training, epochs (can use library/tool \"...\" to get optimal value), and other tweaks\n",
        "# compare confusion matrix with previously built 3X64 CNN model - use the best one\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxzdkm5UBWtK",
        "colab_type": "text"
      },
      "source": [
        "# Confusion Matrix\n",
        "-Plot Predicted labels vs True labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vABEIu0_kwPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# insert code (included above)\n",
        "#.\n",
        "#.\n",
        "#.\n",
        "# cm_plot_labels = ['empty', 'occupied']\n",
        "# plot_confusion_matrix(cm, cm_plot_labels, title= 'Confusion Matrix')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQenwduGk7fA",
        "colab_type": "text"
      },
      "source": [
        "# Saving the VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaEc6QysmcSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('SpotNN_vgg16.h5') # will save to directory where the code is executed by default unless path is specified\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTdWp-wnQ8v",
        "colab_type": "text"
      },
      "source": [
        "# Loading saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6u53iUMnVYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# new_model = load_model('SpotNN_vgg16.h5')\n",
        "\n",
        "# new_model.summary() # will yeild same architecture that allows for recreating the model, the weights, training configuration i.e. loss, optimizer, state of optimizer that allows resuming training from exactly where it was left off\n",
        "# new_model.get_weights()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Cl_foPojmE",
        "colab_type": "text"
      },
      "source": [
        "# To save only the architecture of the Model: json\n",
        "-weights and training configuration excluded\n",
        "\n",
        "and model reconstructions from JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0_f3vvorCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # saving as JSON\n",
        "# json_string = model.to_json()\n",
        "\n",
        "# # saving as YAML\n",
        "# #yaml_string = model.to_yaml\n",
        "\n",
        "# json_string\n",
        "\n",
        "# # reconstruction of model from JSON\n",
        "# from keras.models import model_from_json\n",
        "\n",
        "# model_architecture = model_from_json(json_string)\n",
        "\n",
        "# #model reconstruction from YAML\n",
        "# # from keras.models import model_from_yaml\n",
        "# # model = model_from_yaml(yaml_string)\n",
        "\n",
        "# model_architecture.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnbKH1rcqp4j",
        "colab_type": "text"
      },
      "source": [
        "# To save only Weights of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXJ7CLi4qwDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save_weights('vgg16_model_weights.h5')\n",
        "# model2 = Sequential([\n",
        "#                      Dense(16, input_shape=(1,), activation='relu'),\n",
        "#                      Dense(32, activation='relu'),\n",
        "#                      Dense(2, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model2.load_weights('vgg16_model_weights.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbuoPcz27r8j",
        "colab_type": "text"
      },
      "source": [
        "# Deploy Model to Web Service- Using Flask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7woMib73BG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install Flask\n",
        "pip install Flask\n",
        "# conda install -c anaconda flask\n",
        "\n",
        "# webservice- create python file under eg. \"home_dir\"/flask_apps/sample_app.py\n",
        "\n",
        "from flask import Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/sample') # sample set as endpoint\n",
        "# followed by fn() when user accesses the endpoint\n",
        "def running():\n",
        "  return 'Flask is running!'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}