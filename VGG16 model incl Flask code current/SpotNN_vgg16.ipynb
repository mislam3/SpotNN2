{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpotNN_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReN8gPeav2z5",
        "colab_type": "text"
      },
      "source": [
        "@author: Md Siamul Islam\n",
        "# Parking Spot Vacancy/Occupancy recognition deep NN solution-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUTdUERUbzPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-req (if required)\n",
        "\n",
        "# keras- high-level NN API- CPU&GPU compatibility - backend engine supports: Theano, Tensorflow by default, or CNTK\n",
        "# saving keras models to disk: use HDF5 or h5py\n",
        "# can use Theano for Linus systems - running for first time creates JSON but if reconfiguration necessary: create the file and configure backend\n",
        "# $ pwd\n",
        "# $ mkdir .keras\n",
        "# $ cd .keras/\n",
        "# /.keras$ touch keras.JSON/.keras$ vim keras.json\n",
        "# go to INSERT mode and enter\n",
        "# {\n",
        "# \"image_data_format\":\"channels_first\",\n",
        "# \"epsilon\": le-07,\n",
        "# \"floatx\": \"float32\",\n",
        "# \"backend\": \"theano\"\n",
        "# }\n",
        "# ~\n",
        "# ~\n",
        "# //use \"image_dim_ordering\": \"th\", for first parameter for older keras version or \"tf\" for tensorflow\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwwcSFOht9i",
        "colab_type": "text"
      },
      "source": [
        "Getting Reproducable results -eliminate randomness - can be good for demo purposes\n",
        "- setting Random Seed- before building and training the model- random vars  generated same w/ fixed  random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzBGu6fnisJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import random as rn\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "\n",
        "# import os\n",
        "# os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "# # Set seed for random numbers generated by numpy\n",
        "# np.random.seed(43)\n",
        "\n",
        "# # set seed for python random numbers\n",
        "# rn.seed(1254)\n",
        "\n",
        "# # set seed for Tensorflow rand number\n",
        "# tf.set_random_seed(78)\n",
        "\n",
        "\n",
        "# from keras import backend as k\n",
        "\n",
        "# # forcing tensorflow to use single thread\n",
        "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# k.set_session(sess)\n",
        "\n",
        "# all keras codes follow this code block"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iu5s9ll3qOo",
        "colab_type": "text"
      },
      "source": [
        "# VGG16 model ver 2\n",
        "# fine tuned with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wrw6DzZ3xHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2627c780-b840-429c-ad17-273cca654ce6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as k\n",
        "#from tensorflow import keras\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Sequential\n",
        "from keras.layers import Activation\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "#from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "vgg16_model = keras.applications.vgg16.VGG16()\n",
        "vgg16_model.summary()  # can work on 1000 different categories but need only 2 - need to modify the model for our purpose\n",
        "\n",
        "# .model -transform into Sequential model(object)\n",
        "type(vgg16_model)\n",
        "\n",
        "model = Sequential() # model set to sequential object -currently model has no layers\n",
        "# iterating over all layers within vgg16 model and adding those layers to the sequential model\n",
        "# now we have a model of sequential type and don't need to work with functional API\n",
        "# for layer in vgg16_model.layers:\n",
        "#     model.add(layer)\n",
        "\n",
        "# alternatively, iterating over all except last layer in vgg16, adding to seq model- no pop() required\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "  model.add(layer)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model classifies images- 1 of 1000 categories, not what we want- need to take off the last predictions output dense layer- use pop()\n",
        "# model.layers.pop()\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# no longer working on VGG16 model variable but the new model variable which is a sequential model\n",
        "# setting the layers shown in summary to false to freeze/exclude in future training so the weights are not updated\n",
        "# good for fine  tuning a model -don't need to update layer weights and keep them same\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# instead of the last prediction layer that we popped off,\n",
        "# a new dense layer is added to the model that classifies images to two categories -for 'empty' and 'occupied'\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XogVcAAAbscu",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Data for training using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8hKmaWgr_cp",
        "colab_type": "text"
      },
      "source": [
        "# Image Preparation\n",
        "-for VGG16 image clasifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGNn4UyNsDKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize directory structure - place image on disk (unless using libraries to handle this)\n",
        "# eg: directories: test, train, valid in some directory spot\n",
        "# eg: spot/train/ has directories: empty and occupied containing images corresponding to those labels\n",
        "# eg valid directory has empty and occupied directories with images for validation - set validation % parameter- between 0 and 1- to take from dataset\n",
        "# typically dump all sorts of unorganized labelled images into test directory; but for known labelled images to test, may create empty and occupied folders w/images to test on\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXLnx5zgcItl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# train_labels = [] # corresponding label for sample - needs to be in numpy array\n",
        "# train_samples = [] # actual image data - numpy array or list of numpy array for eg num data purpose\n",
        "\n",
        "train_path = 'content/sample_data/train'\n",
        "test_path = 'content/sample_data/test'\n",
        "valid_path = 'content/sample_data/valid'\n",
        "\n",
        "# ImageDataGenerator -keras object- to get it formatted to be used by keras model\n",
        "# creates batches of normalized data\n",
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=28)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=4)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=10)\n",
        "\n",
        "# Plotting image with labels on Jupyter Notebook- from git\n",
        "def plots(ims, figsize(12,6), rows=1, interp=False, title=None):\n",
        "  if type(ims[0]) is np.ndarray:\n",
        "    ims = np.array(ims).astype(np.uint8)\n",
        "    if(ims.shape[-1] != 3):\n",
        "      ims = ims.transpose((0,2,3,1))\n",
        "      f = plt.figure(figsize=figsize)\n",
        "      cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "      for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "          sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "\n",
        "imgs, labels = next(train_batches) # gets another batch of size 10 from total of images in training set - gets new batch every time its plotted/run\n",
        "plots(imgs, titles=labels)        # observe labels and see if correct and uniform- encoding - eg: [1. 0.] and [0. 1.] for empty and occupied respectively or vice versa\n",
        "# or might use Binary classification instead of categorical to get 1 or 0 i.e 1-D label instead of 2D vector format above \n",
        "\n",
        "# To view which label belongs to which class as assigned by VGG:\n",
        "test_batches.class_indices   # call on the image data generators -returns the dictionary containing mapping from class names to class indices\n",
        "# returned value corresponds the ....................\n",
        "\n",
        "\n",
        "\n",
        "# include code block for grayscale conversion, img normalization-eg.size, etc. & other pre-processing as desired\n",
        "\n",
        "\n",
        "# Data Augmentation (optional)- modify existing data to create new data for training- if dataset is small/larger, varied dataset benefitial -may use Keras\n",
        "# -eg. flip horizontally/vertically, rotate, zoom in/out, vary color, crop \n",
        "# may reduce overfitting\n",
        "\n",
        "# insert code-block\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKa3Cuz-30rI",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhRXiZXKBc5E",
        "colab_type": "text"
      },
      "source": [
        "# Train the new vgg16 model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7rcVv70Bk40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the new model using Adam optimization function with learning rate 0.0001 and provided functions and metrics\n",
        "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# passing in images from image data generator(code block missing) in training set, steps_per_epoch= (images in dataset)/(batch size), valid set generated from image generator(missing code block),\n",
        "# ..., verbose set to level 2\n",
        "model.fit_generator(train_batches, steps_per_epoch=7,\n",
        "                    validation_data=valid_batches, validation_steps=4, epochs=9, verbose =2)\n",
        "\n",
        "# observe metrics from training- compare with 3X64 node CNN created previously- use the better one\n",
        "# also check for overfitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_r9IplIkzXZ",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmspzMqOk51X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "test_imgs, test_labels = next(test_batches)\n",
        "plots(test_imgs, titles=test_labels)\n",
        "\n",
        "# 0th index so that empty/occupied gets values 0/1 or vice versa\n",
        "test_labels = test_labels[:,0]\n",
        "\n",
        "# set steps according to : test set image count (eg. 10) and batch size: (eg. 10), so it takes 1 step to run through the batch of imgs\n",
        "predictions = model.predict_generator(test_batches, steps=1, verbose=0)\n",
        "\n",
        "# create confusion matrix variable\n",
        "cm = confusion_matrix(test_labels, np.round(predictions[:,0]))\n",
        "\n",
        "cm_plot_labels = ['empty', 'occupied']\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix') # plots predicted labels vs true labels on x-y axis -observe values\n",
        "# accuracy might depend on amount of data used for training, epochs (can use library/tool \"...\" to get optimal value), and other tweaks\n",
        "# compare confusion matrix with previously built 3X64 CNN model - use the best one\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxzdkm5UBWtK",
        "colab_type": "text"
      },
      "source": [
        "# Confusion Matrix\n",
        "-Plot Predicted labels vs True labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vABEIu0_kwPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# insert code (included above)\n",
        "#.\n",
        "#.\n",
        "#.\n",
        "# cm_plot_labels = ['empty', 'occupied']\n",
        "# plot_confusion_matrix(cm, cm_plot_labels, title= 'Confusion Matrix')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQenwduGk7fA",
        "colab_type": "text"
      },
      "source": [
        "# Saving the VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaEc6QysmcSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('SpotNN_vgg16.h5') # will save to directory where the code is executed by default unless path is specified\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTdWp-wnQ8v",
        "colab_type": "text"
      },
      "source": [
        "# Loading saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6u53iUMnVYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# new_model = load_model('SpotNN_vgg16.h5')\n",
        "\n",
        "# new_model.summary() # will yeild same architecture that allows for recreating the model, the weights, training configuration i.e. loss, optimizer, state of optimizer that allows resuming training from exactly where it was left off\n",
        "# new_model.get_weights()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Cl_foPojmE",
        "colab_type": "text"
      },
      "source": [
        "# To save only the architecture of the Model: json\n",
        "-weights and training configuration excluded\n",
        "\n",
        "and model reconstructions from JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0_f3vvorCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # saving as JSON\n",
        "# json_string = model.to_json()\n",
        "\n",
        "# # saving as YAML\n",
        "# #yaml_string = model.to_yaml\n",
        "\n",
        "# json_string\n",
        "\n",
        "# # reconstruction of model from JSON\n",
        "# from keras.models import model_from_json\n",
        "\n",
        "# model_architecture = model_from_json(json_string)\n",
        "\n",
        "# #model reconstruction from YAML\n",
        "# # from keras.models import model_from_yaml\n",
        "# # model = model_from_yaml(yaml_string)\n",
        "\n",
        "# model_architecture.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnbKH1rcqp4j",
        "colab_type": "text"
      },
      "source": [
        "# To save only Weights of the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXJ7CLi4qwDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save_weights('vgg16_model_weights.h5')\n",
        "# model2 = Sequential([\n",
        "#                      Dense(16, input_shape=(1,), activation='relu'),\n",
        "#                      Dense(32, activation='relu'),\n",
        "#                      Dense(2, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model2.load_weights('vgg16_model_weights.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbuoPcz27r8j",
        "colab_type": "text"
      },
      "source": [
        "# Deploy Model to Web Service- Using Flask --continue to next- ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klRuicAnWzw8",
        "colab_type": "text"
      },
      "source": [
        "Ignore next code block --continue from predict_app.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7woMib73BG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "5af3a41f-d21a-4e56-a819-906ba8dea2f6"
      },
      "source": [
        "# sample_app.py\n",
        "# very basic info below for explanation/docu purposes(skip to uncommented code segment)\n",
        "# Web app makes an http/? call/request to a Flask web service (backend written in Python) hosting the VGG16 model\n",
        "# -requests model a prediction for the provided image- response received by the webpage/app (can be written in any language)\n",
        "# Flask- microFramework/minimal web-application framework in Python\n",
        "\n",
        "# install Flask\n",
        "# !pip install Flask\n",
        "# conda install -c anaconda flask\n",
        "\n",
        "# webservice- create python file under eg. \"home_dir\"/flask_apps/sample_app.py\n",
        "\n",
        "# from flask import Flask\n",
        "# app = Flask(__name__)  #creates instance of flask class, __name__ name of applications module- used for single module\n",
        "\n",
        "# @app.route('/sample') # sample set as endpoint\n",
        "# followed by fn() when user accesses/browses to the specified '/sample' or '\"ip-address\"/sample' endpoint -outputs 'flask is running'\n",
        "# def running():\n",
        "#   return 'Flask is running!'\n",
        "\n",
        "# enter terminal and type in:\n",
        "#~/flask_apps$ export FLASK_APP=sample_app.py\n",
        "# here working directory is flask_apps/.   cd to directory or provide full path if not in dir\n",
        "\n",
        "#~/flask_apps$ flask run --host=0.0.0.0    # starts flask; host parameter specified makes the web service visible and publicly available to all computers on the network- if not specified: access from local machine only\n",
        "\n",
        "# default port: 5000\n",
        "# http://localhost:5000/sample  # sample is endpoint created for service - access from local machine - else, get ip address on machine running Flask -for remote machine to browse to: eg: 10.0.0.5:5000/sample\n",
        "# displays \" Flask is running\"  - log in information displayed in terminal\n",
        "# pass or request data to flask from Front End and receive a response from the back end web service flask\n",
        "\n",
        "# Sending and Receiving Data using Flask\n",
        "\n",
        "# host web service & web app -Flask\n",
        "\n",
        "\n",
        "# set up directory structure\n",
        "# eg: under flask_apps, create a \"static\" directory to store static files ex: html that flask serves the webpage for webapp. Put python code under flask_apps.\n",
        "# \n",
        "\n",
        "# from flask import request\n",
        "# from flask import jsonify\n",
        "# from flask import Flask\n",
        "\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# To send data to webserver, use eg: \n",
        "# @app.route('/greet',methods=['POST']) \n",
        "# #methods parameter: what kinds of http request are allowed for this endpoint - 'POST' : indicates send data to the server along with the request: sends name to flask webservice- name entered= data contained in http post request sent from webapp to 'greet' endpoint\n",
        "\n",
        "\n",
        "# def greet():  # todo when post request received from endpoint\n",
        "      # message = request.get_json(force=True) # request.: to access data sent to endpoint; get_json on request: gives message from client in JSON- key,value pairs \n",
        "      # name = message['name']\n",
        "      # response = {   # sends back to webapp\n",
        "      #     'greeting': 'Howdy, ' + name + '!'   # dictionary...\n",
        "      # }\n",
        "      # return jsonify(response)   # converts python dictionary to json -> json to webapp\n",
        "\n",
        "\n",
        "\n",
        "# cd to flask_apps dir\n",
        "# export FLASK_APP=hello_app.py      \n",
        "# flask run --host=0.0.0.0\n",
        "\n",
        "#backend now running\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# from flask import request\n",
        "# from flask import jsonify\n",
        "# from flask import Flask\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEibeKFjWan9",
        "colab_type": "text"
      },
      "source": [
        "# Deploy Model to Web Service- Using Flask\n",
        "# predict_app.py\n",
        "### Modify as required for FrontEnd/BackEnd spec \n",
        "### Follow instructions to execute successfully -in.prog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp-Y76hoWfDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict_app.py\n",
        "# Build backend Flask application to host VGG16 model for predictions\n",
        "# under flask_apps directory, create predict_app.py file containing code for web service. Place vgg16 model in form of .h5 file within this dir.\n",
        "# may organize front end files here in appropriate directories and specify/mod paths in code\n",
        "# Modify as required for FrontEnd/BackEnd spec\n",
        "\n",
        "\n",
        "#code for predict app\n",
        "import numpy as np\n",
        "import base64\n",
        "from flask import jsonify\n",
        "from flask import Flask\n",
        "from flask import request\n",
        "import io\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "app = Flask(__name__)  # instance of flask class created\n",
        "\n",
        "def get_model():\n",
        "  global model\n",
        "  model = load_model('SpotNN_vgg16.h5')    # load the saved vgg16 model into memory\n",
        "  print(\" * Model is Loaded!\")\n",
        "\n",
        "\n",
        "def preprocess_image(image, target_size):\n",
        "  if image.mode != \"RGB\":\n",
        "      image = image.convert(\"RGB\")\n",
        "  image = image.resize(target_size)\n",
        "  image = img_to_array(image)   # to numpy array\n",
        "  image= np.expand_dims(image, axis=0)  # expands the dimensions of img\n",
        "\n",
        "  return image    # preprocessed image returned to be passed to keras model\n",
        "\n",
        "\n",
        "print(\" * Loading VGG16 Keras model...\")\n",
        "get_model()  # model loaded into memory - doesn't require reloading every time a request comes into endpoint\n",
        "\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])   # Endpoint: \"/predict\"  -image data sent to endpoint to GET prediction\n",
        "def predict():\n",
        "    message = request.get_json(force=True)\n",
        "    encoded = message['image']  # encoded assigned value associated with key called image json data stored in message variable -atleast one (key,value) pair where key = image, value associated with key is base64 encoded image sent by client\n",
        "    decoded = base64.b64decode(encoded) # now decoded assigned decoded img data\n",
        "    image = Image.open(io.BytesIO(decoded))  # image object with the decoded message\n",
        "    processed_image = preprocess_image(image, target_size=(224,224))   # preprocess then pass it to model for prediction\n",
        "\n",
        "    prediction = model.predict(processed_image).tolist()   # returns numpy array with predictions\n",
        "\n",
        "# send this prediction as JSON back to the client\n",
        "    response = {\n",
        "        'prediction':{     # dictionary with key called prediction\n",
        "            'empty': prediction[0][0],  # empty key set to 0th element of 0th list of prediction list\n",
        "            'occupied': prediction[0][1]    # occupied key set to 1st element of 0th list of prediction list\n",
        "        }    # only 1 image predicted, so prediction list contains only 1 embedded list with probability for empty and probability for occupied\n",
        "    }\n",
        "    return jsonify(response)    # converts python dictionary to JSON--return JSON to FrontEnd\n",
        "\n",
        "\n",
        "# type into powershell/.../...\n",
        "\n",
        "# ~/flask_apps$ export FLASK_APP=predict_app.py\n",
        "# ~/flask_apps$ flask run --host=0.0.0.0\n",
        "\n",
        "# output:\n",
        "# Using XXXX backend.\n",
        "# * Loading Keras model...\n",
        "# * Model loaded!\n",
        "# * Serving Flask app \"predict_app\"\n",
        "# * Running on http://0.0.0.0:5000/ (press CTRL+C to quit)\n",
        "\n",
        "\n",
        "# For Powershell in windows machines: \n",
        "# Powershell: Access image >>Format image data >>Make HTTP POST request >>Get Response for img\n",
        "# PS C:\\imgs> $fileName = 'C:\\pics\\empty3.PNG'\n",
        "# PS C:\\imgs> $bytes = [IO.File]::ReadyAllBytes($fileName)\n",
        "# PS C:\\imgs> $base64Image = [Convert]::ToBase64String($bytes)\n",
        "# PS C:\\imgs> $message = @{ image = $base64Image }\n",
        "# PS C:\\imgs> $jsonified = ConvertTo-Json $message\n",
        "# PS C:\\imgs> $response = Invoke-RestMethod -Method Post -Url \"http\"//??.?.?.?:5000/predict\" -Body $jsonified\n",
        "# PS C:\\imgs> $response.prediction | format-list\n",
        "\n",
        "# sample output:\n",
        "\n",
        "# empty:    X.XXXXXXXXXXXE-XX\n",
        "# occupied: X.XXXXXXXXXXXXXXX\n",
        "\n",
        "# or Curl to use with Bash terminal:\n",
        "# ..MINGW64 /c/imgs\n",
        "# $ fileName=C\\:/imgs/empty3.PNG\n",
        "# ..MINGW64 /c/imgs\n",
        "# $ base64Image=$(base64 $fileName)\n",
        "# ..MINGW64 /c/imgs\n",
        "# $ jsonified=\"{\\\"image\\\":\\\"${base64Image}\\\"}\"\n",
        "# ..MINGW64 /c/imgs\n",
        "# $ echo $jsonified >> data.json\n",
        "# ..MINGW64 /c/imgs\n",
        "# $curl -X POST --data @data.json http://??.?.?.?:5000/predict\n",
        "\n",
        "# sample output:\n",
        "# .\n",
        "# .\n",
        "# .\n",
        "# .\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHX7UxTJkvTb",
        "colab_type": "text"
      },
      "source": [
        "# Make the Front-End Web App to call the predict endpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oBWzNjok9fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}