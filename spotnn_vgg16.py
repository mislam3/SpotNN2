# -*- coding: utf-8 -*-
"""SpotNN_vgg16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Bt3h3w5yOsWca_JaB3zqalcz09UfASz

@author: Md Siamul Islam
# Parking Spot Vacancy/Occupancy recognition deep NN solution-VGG16
"""

# pre-req (if required)

# keras- high-level NN API- CPU&GPU compatibility - backend engine supports: Theano, Tensorflow by default, or CNTK
# saving keras models to disk: use HDF5 or h5py
# can use Theano for Linus systems - running for first time creates JSON but if reconfiguration necessary: create the file and configure backend
# $ pwd
# $ mkdir .keras
# $ cd .keras/
# /.keras$ touch keras.JSON/.keras$ vim keras.json
# go to INSERT mode and enter
# {
# "image_data_format":"channels_first",
# "epsilon": le-07,
# "floatx": "float32",
# "backend": "theano"
# }
# ~
# ~
# //use "image_dim_ordering": "th", for first parameter for older keras version or "tf" for tensorflow

"""# VGG16 model ver 2
# fine tuned with Keras
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import keras
from keras import backend as k
#from tensorflow import keras
from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.layers.core import Dense, Flatten
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
from keras.layers.convolutional import *
from matplotlib import pyplot as plt
# %matplotlib inline
from sklearn.metrics import confusion_matrix
import itertools
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras import Sequential
from keras.layers import Activation
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
#from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization
from tensorflow.keras import layers



vgg16_model = keras.applications.vgg16.VGG16()
vgg16_model.summary()  # can work on 1000 different categories but need only 2 - need to modify the model for our purpose

# .model -transform into Sequential model(object)
type(vgg16_model)

model = Sequential() # model set to sequential object -currently model has no layers
# iterating over all layers within vgg16 model and adding those layers to the sequential model
# now we have a model of sequential type and don't need to work with functional API
# for layer in vgg16_model.layers:
#     model.add(layer)

# alternatively, iterating over all except last layer in vgg16, adding to seq model- no pop() required
for layer in vgg16_model.layers[:-1]:
  model.add(layer)

model.summary()

# model classifies images- 1 of 1000 categories, not what we want- need to take off the last predictions output dense layer- use pop()
# model.layers.pop()
# model.summary()


# no longer working on VGG16 model variable but the new model variable which is a sequential model
# setting the layers shown in summary to false to freeze/exclude in future training so the weights are not updated
# good for fine  tuning a model -don't need to update layer weights and keep them same
for layer in model.layers:
    layer.trainable = False

# instead of the last prediction layer that we popped off,
# a new dense layer is added to the model that classifies images to two categories -for 'empty' and 'occupied'
model.add(Dense(2, activation='softmax'))
model.summary()

"""# Preprocessing Data for training using keras

# Image Preparation
-for VGG16 image clasifier
"""

# organize directory structure - place image on disk (unless using libraries to handle this)
# eg: directories: test, train, valid in some directory spot
# eg: spot/train/ has directories: empty and occupied containing images corresponding to those labels
# eg valid directory has empty and occupied directories with images for validation - set validation % parameter- between 0 and 1- to take from dataset
# typically dump all sorts of unorganized labelled images into test directory; but for known labelled images to test, may create empty and occupied folders w/images to test on

import numpy as np
from random import randint
from sklearn.preprocessing import MinMaxScaler

# train_labels = [] # corresponding label for sample - needs to be in numpy array
# train_samples = [] # actual image data - numpy array or list of numpy array for eg num data purpose

train_path = 'content/sample_data/train'
test_path = 'content/sample_data/test'
valid_path = 'content/sample_data/valid'

# ImageDataGenerator -keras object- to get it formatted to be used by keras model
# creates batches of normalized data
train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=28)
valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=4)
test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['empty', 'occupied'], batch_size=10)

# Plotting image with labels on Jupyter Notebook- from git
def plots(ims, figsize(12,6), rows=1, interp=False, title=None):
  if type(ims[0]) is np.ndarray:
    ims = np.array(ims).astype(np.uint8)
    if(ims.shape[-1] != 3):
      ims = ims.transpose((0,2,3,1))
      f = plt.figure(figsize=figsize)
      cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1
      for i in range(len(ims)):
        sp = f.add_subplot(rows, cols, i+1)
        sp.axis('Off')
        if titles is not None:
          sp.set_title(titles[i], fontsize=16)
        plt.imshow(ims[i], interpolation=None if interp else 'none')


imgs, labels = next(train_batches) # gets another batch of size 10 from total of images in training set - gets new batch every time its plotted/run
plots(imgs, titles=labels)        # observe labels and see if correct and uniform- encoding - eg: [1. 0.] and [0. 1.] for empty and occupied respectively or vice versa


# include code block for grayscale conversion, img normalization-eg.size, etc. & other pre-processing as desired

"""---------------------------------------------------------------------------------------------------------------------------------------------

# Train the new vgg16 model
"""

# compile the new model using Adam optimization function with learning rate 0.0001 and provided functions and metrics
model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# passing in images from image data generator(code block missing) in training set, steps_per_epoch= (images in dataset)/(batch size), valid set generated from image generator(missing code block),
# ..., verbose set to level 2
model.fit_generator(train_batches, steps_per_epoch=7,
                    validation_data=valid_batches, validation_steps=4, epochs=9, verbose =2)

# observe metrics from training- compare with 3X64 node CNN created previously- use the better one
# also check for overfitting

"""# Predictions"""

#
test_imgs, test_labels = next(test_batches)
plots(test_imgs, titles=test_labels)

# 0th index so that empty/occupied gets values 0/1 or vice versa
test_labels = test_labels[:,0]

# set steps according to : test set image count (eg. 10) and batch size: (eg. 10), so it takes 1 step to run through the batch of imgs
predictions = model.predict_generator(test_batches, steps=1, verbose=0)

# create confusion matrix variable
cm = confusion_matrix(test_labels, np.round(predictions[:,0]))

cm_plot_labels = ['empty', 'occupied']
plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix') # plots predicted labels vs true labels on x-y axis -observe values
# accuracy might depend on amount of data used for training, epochs (can use library/tool "..." to get optimal value), and other tweaks
# compare confusion matrix with previously built 3X64 CNN model - use the best one

"""# Confusion Matrix
-Plot Predicted labels vs True labels
"""

# insert code (included above)
#.
#.
#.
# cm_plot_labels = ['empty', 'occupied']
# plot_confusion_matrix(cm, cm_plot_labels, title= 'Confusion Matrix')

"""# Saving the VGG16 Model"""

model.save('SpotNN_vgg16.h5') # will save to directory where the code is executed by default unless path is specified

"""# Loading saved model"""

# from keras.models import load_model

# new_model = load_model('SpotNN_vgg16.h5')

# new_model.summary() # will yeild same architecture that allows for recreating the model, the weights, training configuration i.e. loss, optimizer, state of optimizer that allows resuming training from exactly where it was left off
# new_model.get_weights()

"""# To save only the architecture of the Model: json
-weights and training configuration excluded

and model reconstructions from JSON
"""

# # saving as JSON
# json_string = model.to_json()

# # saving as YAML
# #yaml_string = model.to_yaml

# json_string

# # reconstruction of model from JSON
# from keras.models import model_from_json

# model_architecture = model_from_json(json_string)

# #model reconstruction from YAML
# # from keras.models import model_from_yaml
# # model = model_from_yaml(yaml_string)

# model_architecture.summary()

"""# To save only Weights of the model"""

# model.save_weights('vgg16_model_weights.h5')
# model2 = Sequential([
#                      Dense(16, input_shape=(1,), activation='relu'),
#                      Dense(32, activation='relu'),
#                      Dense(2, activation='softmax')
# ])

# model2.load_weights('vgg16_model_weights.h5')

"""# Deploy Model to Web Service- Using Flask"""

# install Flask
pip install Flask
# conda install -c anaconda flask

# webservice- create python file under eg. "home_dir"/flask_apps/sample_app.py

from flask import Flask
app = Flask(__name__)

@app.route('/sample') # sample set as endpoint
# followed by fn() when user accesses the endpoint
def running():
  return 'Flask is running!'